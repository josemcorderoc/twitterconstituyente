{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ths notebook contains the code for downloading the Twitter data of candidates for the Conventional Constitution.\n",
    "\n",
    "- Input: candidates Twitter IDs\n",
    "- Output: downloaded tweets (in MongoDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import tweepy\n",
    "from tweepy import TweepError\n",
    "import os\n",
    "import pymongo\n",
    "from pymongo.errors import BulkWriteError\n",
    "import logging\n",
    "import time\n",
    "import tqdm\n",
    "import pyathena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='[%(asctime)s] - %(name)s - %(funcName)s - %(levelname)s : %(message)s', level=logging.INFO)\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "load_dotenv()  # take environment variables from .env.\n",
    "\n",
    "auth = tweepy.OAuthHandler(os.environ[\"TWITTER_API_KEY\"], os.environ[\"TWITTER_API_SECRET_KEY\"])\n",
    "auth.set_access_token(os.environ[\"TWITTER_ACCESS_TOKEN\"], os.environ[\"TWITTER_ACCESS_TOKEN_SECRET\"])\n",
    "\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)\n",
    "\n",
    "mongo_client = pymongo.MongoClient(os.environ[\"MONGODB_URL\"])\n",
    "twitter_db = mongo_client.TwitterConstituyenteDB\n",
    "test_db = mongo_client.testdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = pyathena.connect(s3_staging_dir=os.environ[\"AWS_ATHENA_S3_STAGING_DIR\"], \n",
    "        region_name=os.environ[\"AWS_REGION\"])\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT * FROM \"twitter-constituyente\".\"constituyentes_full\";\n",
    "\"\"\"\n",
    "candidates_df = pd.read_sql(query, conn)\n",
    "candidates_df[\"electoral_district\"] = candidates_df[\"electoral_district\"].astype(\"str\")\n",
    "\n",
    "candidates_ids = candidates_df[\"user__id_str\"].dropna().to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bulk_write_to_mongo(collection, data):\n",
    "    to_insert = len(data)\n",
    "    try:\n",
    "        if to_insert > 0:\n",
    "            collection.insert_many(data, ordered=False)\n",
    "        return to_insert, 0\n",
    "    except BulkWriteError as e:\n",
    "        log.error(\"BulkWriteError\")\n",
    "        inserted = e.details[\"nInserted\"]\n",
    "        return inserted, to_insert - inserted\n",
    "\n",
    "def download_timeline(user_id: str, n: int = 3200, count: int = 200, trim_user=True, tweet_mode=\"extended\", **kwargs):\n",
    "    log.info(f'Downloading timeline from user id: {user_id}') \n",
    "    start_time = time.time()\n",
    "    tweets = [status for status in tqdm.tqdm(tweepy.Cursor(\n",
    "        api.user_timeline, \n",
    "        user_id=user_id, \n",
    "        count=count, \n",
    "        trim_user=trim_user, \n",
    "        tweet_mode=tweet_mode,\n",
    "        **kwargs).items(n), total=n)]\n",
    "    total_time = time.time()  - start_time\n",
    "    log.info(f\"Downloaded finished: {len(tweets)} tweets in {total_time:.4f} seconds.\")\n",
    "    return tweets\n",
    "\n",
    "\n",
    "def download_retweets(tweet_id: str, trim_user=True, tweet_mode=\"extended\"):\n",
    "    return api.retweets(tweet_id, count=100, trim_user=trim_user, tweet_mode=tweet_mode)\n",
    "\n",
    "def download_users(user_ids):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  ids of tweets in those time ranges\n",
    "dic31_2020_id = 1344795494015528970\n",
    "may15_2021_id = 1393748045909667840\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download feed from candidates\n",
    "for user_id_str in tqdm.tqdm(candidates_df[\"user__id_str\"].dropna().sample(10)):\n",
    "    try:\n",
    "        timeline = download_timeline(user_id_str, since_id=dic31_2020_id, max_id=may15_2021_id)\n",
    "        writed, not_writed = bulk_write_to_mongo(twitter_db.tweetstest, list(map(lambda status: status._json, timeline)))\n",
    "        log.info(f\"Writed: {writed}. Not writed: {not_writed}\")\n",
    "    except Exception as e:\n",
    "        log.error(f\"Error from user id: {user_id_str}\")\n",
    "        log.error(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downloading retweet for each tweet from a candidate\n",
    "\n",
    "filter_original_tweets = {\n",
    "    \"user.id_str\": {\"$in\": candidates_ids},\n",
    "    \"retweeted_status\": { \"$exists\": False },\n",
    "    \"retweet_count\": { \"$gt\": 0}\n",
    "}\n",
    "\n",
    "count_originals = twitter_db.tweets.count_documents(filter_original_tweets)\n",
    "tweets_constituyentes_originales = twitter_db.tweets.find(filter_original_tweets)\n",
    "\n",
    "for tweet in tqdm.tqdm(tweets_constituyentes_originales, total=count_originals):\n",
    "    retweets = download_retweets(tweet[\"id_str\"])\n",
    "    writed, not_writed = bulk_write_to_mongo(twitter_db.tweets, list(map(lambda status: status._json, retweets)))\n",
    "    if writed:\n",
    "        log.info(f\"Writed: {writed}. Not writed: {not_writed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downloading feeds for retweeters\n",
    "\n",
    "retweeters_filter = {\n",
    "    \"user.id_str\": {\"$nin\": candidates_ids },\n",
    "    \"retweeted_status.user.id_str\": { \"$in\": candidates_ids }\n",
    "}\n",
    "retweeters = twitter_db.tweets.find(retweeters_filter, [\"user.id_str\"])\n",
    "\n",
    "for user_id_str in tqdm.tqdm(retweeters):\n",
    "    try:\n",
    "        timeline = download_timeline(user_id_str[\"user\"][\"id_str\"], since_id=dic31_2020_id, max_id=may15_2021_id)\n",
    "    except TweepError as e:\n",
    "        log.error(e)\n",
    "        continue\n",
    "    writed, not_writed = bulk_write_to_mongo(twitter_db.tweets, list(map(lambda status: status._json, timeline)))\n",
    "    log.info(f\"Writed: {writed}. Not writed: {not_writed}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
