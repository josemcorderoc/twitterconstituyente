{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering 2\n",
    "\n",
    "This notebooks generates the final features for each candidate.\n",
    "\n",
    "- Input: feature engineering 1, network metrics\n",
    "- Output: twitter metric features, sentiment features and network features for each candidate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import logging\n",
    "import pymongo\n",
    "import os\n",
    "import pyathena\n",
    "import dotenv\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "#from utils.mongodb import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-01-23 11:55:02,418] - botocore.credentials - load - INFO : Found credentials in environment variables.\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(format='[%(asctime)s] - %(name)s - %(funcName)s - %(levelname)s : %(message)s', level=logging.INFO)\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "dotenv.load_dotenv(os.path.join(module_path, '.env'))\n",
    "\n",
    "mongo_client = pymongo.MongoClient(os.environ[\"MONGODB_URL\"])\n",
    "\n",
    "twitter_db = mongo_client.TwitterConstituyenteDB\n",
    "\n",
    "conn = pyathena.connect(s3_staging_dir=os.environ[\"AWS_ATHENA_S3_STAGING_DIR\"], \n",
    "        region_name=os.environ[\"AWS_REGION\"])\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT * FROM \"twitter-constituyente\".\"constituyentes_full\";\n",
    "\"\"\"\n",
    "candidates_df = pd.read_sql(query, conn)\n",
    "candidates_df[\"electoral_district\"] = candidates_df[\"electoral_district\"].astype(\"str\")\n",
    "candidates_ids = candidates_df[\"user__id_str\"].dropna().to_list()\n",
    "\n",
    "\n",
    "candidates_data_df = candidates_df.dropna(subset=[\"user__id_str\"]).set_index(\"user__id_str\")\n",
    "candidates_data_df[\"rm\"] = candidates_data_df[\"electoral_district\"].isin(list(map(str, range(8, 15)))).astype(\"int\")\n",
    "candidates_data_df[\"district_percentage\"] /= 100\n",
    "\n",
    "district_df = candidates_data_df[[\"electoral_district\"]]\n",
    "percentage_df = candidates_data_df[[\"district_percentage\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading features data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_7d_collection_to_agg_df(collection):\n",
    "  df = pd.DataFrame(collection.find({\"user__id_str\": {\"$in\": candidates_ids}}))\n",
    "  df = (df\n",
    "        .rename(columns={\"window_end\": \"date\"})\n",
    "        .sort_values(\"date\")\n",
    "        .set_index([\"date\", \"user__id_str\"]))\n",
    "  return df\n",
    "\n",
    "network_7d_collections = [\n",
    "  twitter_db.network_metrics_7d_A,\n",
    "  twitter_db.network_metrics_7d_pagerank\n",
    "]\n",
    "\n",
    "network_7d_collections_pop = [\n",
    "  twitter_db.network_metrics_7d_pop_A,\n",
    "  twitter_db.network_metrics_7d_pagerank_pop\n",
    "]\n",
    "\n",
    "network_total_collections = [\n",
    "  twitter_db.network_metrics_A,\n",
    "  twitter_db.network_metrics_pagerank_1,\n",
    "  twitter_db.network_metrics_pagerank_2,\n",
    "  twitter_db.network_metrics_pagerank_3\n",
    "]\n",
    "\n",
    "network_total_collections_pop = [\n",
    "  twitter_db.network_metrics_pop_A,\n",
    "  twitter_db.network_metrics_pagerank_pop                     \n",
    "]\n",
    "\n",
    "\n",
    "def get_raw_network_features():\n",
    "  df1 = pd.concat([network_7d_collection_to_agg_df(col) for col in network_7d_collections], axis=1)\n",
    "  df2 = pd.concat([network_7d_collection_to_agg_df(col) for col in network_7d_collections_pop], axis=1)\n",
    "  return pd.concat([df1, df2.add_suffix(\"__pop\")], axis=1)\n",
    "\n",
    "\n",
    "def get_raw_twitter_sentiment_features():\n",
    "  features_df = (pd.read_parquet(\"./twitter_sentiment_features.parquet\")\n",
    "    .sort_values([\"date\", \"user.id_str\"]).rename(columns={\"user.id_str\":\"user__id_str\"}))\n",
    "  features_df['week_monday'] = features_df['date'].dt.to_period('W').dt.start_time\n",
    "  return features_df.set_index([\"date\", \"user__id_str\"])\n",
    "\n",
    "\n",
    "def get_raw_features(): \n",
    "  return pd.concat([\n",
    "    get_raw_network_features(),\n",
    "    get_raw_twitter_sentiment_features()\n",
    "  ], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_features_df = get_raw_features().reset_index()\n",
    "raw_features_df.columns = raw_features_df.columns.str.lower()\n",
    "\n",
    "def week_avg_raw_features(df, start_date, end_date):\n",
    "    df = df[(df[\"date\"]>=start_date) & (df[\"date\"]<=end_date)].fillna(0)\n",
    "    n_days = (end_date - start_date).days + 1\n",
    "    n_weeks = n_days/7\n",
    "    log.info(f\"number of days: {n_days}, number of weeks: {n_weeks}\")\n",
    "    # promedio semanal = promedio diario * 7\n",
    "    return df.groupby(\"user__id_str\").sum()/n_weeks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all period 18 weeks mean features\n",
    "start = datetime.datetime(2021, 1, 9)\n",
    "middle1 = datetime.datetime(2021, 4, 30)\n",
    "middle2 = datetime.datetime(2021, 5, 1)\n",
    "end = datetime.datetime(2021, 5, 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-01-23 11:58:31,588] - __main__ - week_avg_raw_features - INFO : number of days: 126, number of weeks: 18.0\n"
     ]
    }
   ],
   "source": [
    "week_agg_features_df = week_avg_raw_features(raw_features_df, start, end)\n",
    "week_agg_features_df.reset_index().to_parquet(\"final_features.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First 16 weeks vs Last 2 weeks features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-01-23 11:58:32,680] - __main__ - week_avg_raw_features - INFO : number of days: 112, number of weeks: 16.0\n",
      "[2022-01-23 11:58:32,868] - __main__ - week_avg_raw_features - INFO : number of days: 14, number of weeks: 2.0\n"
     ]
    }
   ],
   "source": [
    "# first 16 weeks - last 2 weeks feature\n",
    "week_agg_features_first16_df = week_avg_raw_features(raw_features_df, start, middle1)\n",
    "week_agg_features_first16_df.reset_index().to_parquet(\"final_features_first16weeks.parquet\", index=False)\n",
    "\n",
    "\n",
    "week_agg_features_last2_df = week_avg_raw_features(raw_features_df, middle2, end)\n",
    "week_agg_features_last2_df.reset_index().to_parquet(\"final_features_last2weeks.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List aggregated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_agg_base_df = week_agg_features_df.join(candidates_data_df[[\"electoral_district\", \"list\"]])\n",
    "list_agg_base_df[\"list\"] = list_agg_base_df[\"electoral_district\"].apply(lambda d: f\"D{d}&\") + list_agg_base_df[\"list\"]\n",
    "list_agg_base_df = list_agg_base_df.reset_index(drop=True).drop(columns=[\"electoral_district\"]).groupby(\"list\").sum()\n",
    "\n",
    "# agg features and base features are the same\n",
    "assert list_agg_base_df.columns.to_list() == week_agg_features_df.columns.to_list()\n",
    "list_agg_base_df.reset_index().to_parquet(\"final_features_list_agg.parquet\", index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
